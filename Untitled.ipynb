{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73cbf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.0.284 (from -r requirements.txt (line 1))\n",
      "  Obtaining dependency information for langchain==0.0.284 from https://files.pythonhosted.org/packages/e0/0f/ad9d8095ec147c1b33584b69f287e0e39abef1c2955d834802c3592b0c8d/langchain-0.0.284-py3-none-any.whl.metadata\n",
      "  Using cached langchain-0.0.284-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.0.0)\n",
      "Collecting streamlit==1.22.0 (from -r requirements.txt (line 3))\n",
      "  Using cached streamlit-1.22.0-py2.py3-none-any.whl (8.9 MB)\n",
      "Collecting tiktoken==0.4.0 (from -r requirements.txt (line 4))\n",
      "  Using cached tiktoken-0.4.0-cp311-cp311-macosx_11_0_arm64.whl (761 kB)\n",
      "Requirement already satisfied: faiss-cpu==1.7.4 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (1.7.4)\n",
      "Collecting protobuf~=3.19.0 (from -r requirements.txt (line 6))\n",
      "  Downloading protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from langchain==0.0.284->-r requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from langchain==0.0.284->-r requirements.txt (line 1)) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from langchain==0.0.284->-r requirements.txt (line 1)) (3.8.3)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.284->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for dataclasses-json<0.6.0,>=0.5.7 from https://files.pythonhosted.org/packages/97/5f/e7cc90f36152810cab08b6c9c1125e8bcb9d76f8b3018d101b5f877b386c/dataclasses_json-0.5.14-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from langchain==0.0.284->-r requirements.txt (line 1)) (0.0.44)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from langchain==0.0.284->-r requirements.txt (line 1)) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from langchain==0.0.284->-r requirements.txt (line 1)) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from langchain==0.0.284->-r requirements.txt (line 1)) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from langchain==0.0.284->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from langchain==0.0.284->-r requirements.txt (line 1)) (8.2.2)\n",
      "Collecting altair<5,>=3.2.0 (from streamlit==1.22.0->-r requirements.txt (line 3))\n",
      "  Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: blinker>=1.0.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (1.6.3)\n",
      "Requirement already satisfied: cachetools>=4.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (5.3.1)\n",
      "Requirement already satisfied: click>=7.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (8.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (6.0.0)\n",
      "Requirement already satisfied: packaging>=14.1 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (23.0)\n",
      "Requirement already satisfied: pandas<3,>=0.25 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (1.5.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (9.4.0)\n",
      "Requirement already satisfied: pyarrow>=4.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (11.0.0)\n",
      "Collecting pympler>=0.9 (from streamlit==1.22.0->-r requirements.txt (line 3))\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (13.6.0)\n",
      "Requirement already satisfied: toml in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (4.7.1)\n",
      "Requirement already satisfied: tzlocal>=1.1 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (5.1)\n",
      "Requirement already satisfied: validators>=0.2 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (3.1.37)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (0.8.1b0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from streamlit==1.22.0->-r requirements.txt (line 3)) (6.3.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from tiktoken==0.4.0->-r requirements.txt (line 4)) (2022.7.9)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284->-r requirements.txt (line 1)) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284->-r requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284->-r requirements.txt (line 1)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284->-r requirements.txt (line 1)) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284->-r requirements.txt (line 1)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: entrypoints in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from altair<5,>=3.2.0->streamlit==1.22.0->-r requirements.txt (line 3)) (0.4)\n",
      "Requirement already satisfied: jinja2 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from altair<5,>=3.2.0->streamlit==1.22.0->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from altair<5,>=3.2.0->streamlit==1.22.0->-r requirements.txt (line 3)) (4.17.3)\n",
      "Requirement already satisfied: toolz in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from altair<5,>=3.2.0->streamlit==1.22.0->-r requirements.txt (line 3)) (0.12.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.284->-r requirements.txt (line 1)) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.284->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from gitpython!=3.1.19->streamlit==1.22.0->-r requirements.txt (line 3)) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from importlib-metadata>=1.4->streamlit==1.22.0->-r requirements.txt (line 3)) (3.11.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytz>=2020.1 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from pandas<3,>=0.25->streamlit==1.22.0->-r requirements.txt (line 3)) (2022.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.0.284->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.0.284->-r requirements.txt (line 1)) (2.10.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from python-dateutil->streamlit==1.22.0->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.0.284->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.0.284->-r requirements.txt (line 1)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.0.284->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->streamlit==1.22.0->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->streamlit==1.22.0->-r requirements.txt (line 3)) (2.15.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.22.0->-r requirements.txt (line 3)) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from jinja2->altair<5,>=3.2.0->streamlit==1.22.0->-r requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.22.0->-r requirements.txt (line 3)) (0.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->streamlit==1.22.0->-r requirements.txt (line 3)) (0.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.284->-r requirements.txt (line 1)) (0.4.3)\n",
      "Downloading langchain-0.0.284-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: pympler, protobuf, tiktoken, dataclasses-json, altair, streamlit, langchain\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.24.4\n",
      "    Uninstalling protobuf-4.24.4:\n",
      "      Successfully uninstalled protobuf-4.24.4\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.5.1\n",
      "    Uninstalling tiktoken-0.5.1:\n",
      "      Successfully uninstalled tiktoken-0.5.1\n",
      "  Attempting uninstall: dataclasses-json\n",
      "    Found existing installation: dataclasses-json 0.6.1\n",
      "    Uninstalling dataclasses-json-0.6.1:\n",
      "      Successfully uninstalled dataclasses-json-0.6.1\n",
      "  Attempting uninstall: altair\n",
      "    Found existing installation: altair 5.1.2\n",
      "    Uninstalling altair-5.1.2:\n",
      "      Successfully uninstalled altair-5.1.2\n",
      "  Attempting uninstall: streamlit\n",
      "    Found existing installation: streamlit 1.28.0\n",
      "    Uninstalling streamlit-1.28.0:\n",
      "      Successfully uninstalled streamlit-1.28.0\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.315\n",
      "    Uninstalling langchain-0.0.315:\n",
      "      Successfully uninstalled langchain-0.0.315\n",
      "Successfully installed altair-4.2.2 dataclasses-json-0.5.14 langchain-0.0.284 protobuf-3.19.6 pympler-1.0.1 streamlit-1.22.0 tiktoken-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e92a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GooglePalm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93fdcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"AIzaSyBrUkbIT8BlP_IPVyDgVpODbZI44wbGVQA\"\n",
    "llm = GooglePalm(google_api_key=api_key,temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a3b686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Obtaining dependency information for google-generativeai from https://files.pythonhosted.org/packages/93/1a/1892cb4d1e925fa26f2b83bc8a6bca861f5e8fe6d5e9d9e983548b6d3532/google_generativeai-0.2.2-py3-none-any.whl.metadata\n",
      "  Downloading google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting google-ai-generativelanguage==0.3.3 (from google-generativeai)\n",
      "  Obtaining dependency information for google-ai-generativelanguage==0.3.3 from https://files.pythonhosted.org/packages/8f/66/b5a83cdb4c8cb1d0f64243ae61bfa4e970b5740c2999dfe1bb96725599ab/google_ai_generativelanguage-0.3.3-py3-none-any.whl.metadata\n",
      "  Downloading google_ai_generativelanguage-0.3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting google-auth (from google-generativeai)\n",
      "  Obtaining dependency information for google-auth from https://files.pythonhosted.org/packages/86/a7/75911c13a242735d5aeaca6a272da380335ff4ba5f26d6b2ae20ff682d13/google_auth-2.23.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.23.4-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Obtaining dependency information for google-api-core from https://files.pythonhosted.org/packages/4d/ce/4fd62ea66b3508debc795e475336ce915929765870f0ad52328426ba016e/google_api_core-2.12.0-py3-none-any.whl.metadata\n",
      "  Downloading google_api_core-2.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: protobuf in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from google-generativeai) (3.19.6)\n",
      "Requirement already satisfied: tqdm in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from google-generativeai) (4.65.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0 (from google-ai-generativelanguage==0.3.3->google-generativeai)\n",
      "  Obtaining dependency information for proto-plus<2.0.0dev,>=1.22.0 from https://files.pythonhosted.org/packages/36/5b/e02636d221917d6fa2a61289b3f16002eb4c93d51c0191ac8e896d527182/proto_plus-1.22.3-py3-none-any.whl.metadata\n",
      "  Downloading proto_plus-1.22.3-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Obtaining dependency information for googleapis-common-protos<2.0.dev0,>=1.56.2 from https://files.pythonhosted.org/packages/21/49/12996dc0238e017504dceea1d121a48bd49fb3f4416f40d59fc3e924b4f3/googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from google-auth->google-generativeai) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from google-auth->google-generativeai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth->google-generativeai)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core->google-generativeai)\n",
      "  Obtaining dependency information for grpcio<2.0dev,>=1.33.2 from https://files.pythonhosted.org/packages/da/23/cf7f605f9a87ebcc03a677477d6ba0d012be466d1491c360e52264e33672/grpcio-1.59.2-cp311-cp311-macosx_10_10_universal2.whl.metadata\n",
      "  Downloading grpcio-1.59.2-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core->google-generativeai)\n",
      "  Obtaining dependency information for grpcio-status<2.0.dev0,>=1.33.2 from https://files.pythonhosted.org/packages/ea/4b/d31e321be28de4ea7d2dc00e0ec4b5c47696207bed4ced1b82b5146aa76c/grpcio_status-1.59.2-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.59.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sshaik05/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.7.22)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/86/f5/74106012afe8b14e87c43a20605d495d23bdbb5b4df3913ea77af6401765/protobuf-4.25.0-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading protobuf-4.25.0-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Downloading google_generativeai-0.2.2-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_ai_generativelanguage-0.3.3-py3-none-any.whl (267 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.9/267.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.12.0-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.3/183.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl (230 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.9/230.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.22.3-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.59.2-cp311-cp311-macosx_10_10_universal2.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.59.2-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-4.25.0-cp37-abi3-macosx_10_9_universal2.whl (393 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.9/393.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rsa, protobuf, grpcio, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-api-core, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.22.0 requires protobuf<4,>=3.12, but you have protobuf 4.25.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.3.3 google-api-core-2.12.0 google-auth-2.23.4 google-generativeai-0.2.2 googleapis-common-protos-1.61.0 grpcio-1.59.2 grpcio-status-1.59.2 proto-plus-1.22.3 protobuf-4.25.0 rsa-4.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38f4a366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To my wife,\n",
      "\n",
      "I love the way you make me laugh,\n",
      "Even when I'm feeling down.\n",
      "You always know how to cheer me up,\n",
      "And turn my frown upside down.\n",
      "\n",
      "I love the way you look at me,\n",
      "With those big, beautiful eyes.\n",
      "You make me feel like I'm the only man in the world,\n",
      "And that I can do anything.\n",
      "\n",
      "I love the way you touch me,\n",
      "So soft and gentle.\n",
      "It sends shivers down my spine,\n",
      "And makes me want you more.\n",
      "\n",
      "I love the way you kiss me,\n",
      "So passionately and full of love.\n",
      "It takes my breath away,\n",
      "And makes my heart skip a beat.\n",
      "\n",
      "I love the way you say my name,\n",
      "So sweetly and lovingly.\n",
      "It makes me melt,\n",
      "And makes me want to hold you close.\n",
      "\n",
      "I love the way you love me,\n",
      "So completely and unconditionally.\n",
      "It makes me feel like the luckiest man in the world,\n",
      "To have you as my wife.\n",
      "\n",
      "I love you more than words can say,\n",
      "And I will love you forever.\n"
     ]
    }
   ],
   "source": [
    "poem = llm(\"Write a poem for my wife\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed896a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear HR,\n",
      "\n",
      "I am writing to request a leave of absence for three days, from March 8th to March 10th, 2023.\n",
      "\n",
      "I have a doctor's appointment on March 8th for a medical condition that requires follow-up appointments on March 9th and 10th. I have already completed all of my work for the week, and I have made arrangements for my colleagues to cover my duties while I am out.\n",
      "\n",
      "I apologize for any inconvenience this may cause, and I appreciate your understanding.\n",
      "\n",
      "Sincerely,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "email_temp = llm(\"write a email to HR asking for leave 3 days\")\n",
    "print(email_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a32d2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 kmph\n"
     ]
    }
   ],
   "source": [
    "prblm = llm(\"A train 125 m long passes a man, running at 5 km/hr in the same direction in which the train is going, in 10 seconds. The speed of the train is: slove this\")\n",
    "print(prblm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ad08c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02f8b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=\"codebasics_faqs.csv\",source_column=\"prompt\",encoding='cp1252')\n",
    "data=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75419c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cac6220c8749fb80af39a502242e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)c7233/.gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db52737ffdd042abae1615241679a6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f192a59fdad4e499b982708a0d07575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/2_Dense/config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e663a5cab49f4e59a8a3b19bc23bcaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.15M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77bb526e9fcc4143a106581291a194e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)9fb15c7233/README.md:   0%|          | 0.00/66.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4289c99cd9f940edb237408f6a3f46de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b15c7233/config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7a2e912d79419e8101fac8379c4c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2a90b2eda64f37ad57fc4daf62ad38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47df9d0f6dcf468991b5ac22c3c7929c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17614cb7e2a141fe9b32b35a5239313e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2984edd3e43434d98697d09f744f4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59436ab72c6a454bacdf18888a010e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)c7233/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b70e76f00284ea2aed7b4208545f4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb03f3311f14639b98b9511e812c29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)15c7233/modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "instructor_emb = HuggingFaceInstructEmbeddings()\n",
    "vector_db = FAISS.from_documents(documents=data,embedding=instructor_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e44fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting instructorembedding\n",
      "  Obtaining dependency information for instructorembedding from https://files.pythonhosted.org/packages/6c/fc/64375441f43cc9ddc81f76a1a8f516e6d63f5b6ecb67fffdcddc0445f0d3/InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
      "Installing collected packages: instructorembedding\n",
      "Successfully installed instructorembedding-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install instructorembedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53344d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='prompt: Do you provide any job assistance?\\nresponse: Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters.', metadata={'source': 'Do you provide any job assistance?', 'row': 11}), Document(page_content='prompt: Do you provide any virtual internship?\\nresponse: Yes', metadata={'source': 'Do you provide any virtual internship?', 'row': 14}), Document(page_content='prompt: Will this course guarantee me a job?\\nresponse: We created a much lighter version of this course on YouTube available for free (click this link) and many people gave us feedback that they were able to fetch jobs (see testimonials). Now this paid course is at least 5x better than the YouTube course which gives us ample confidence that you will be able to get a job. However, we want to be honest and do not want to make any impractical promises! Our guarantee is to prepare you for the job market by teaching the most relevant skills, knowledge & timeless principles good enough to fetch the job.', metadata={'source': 'Will this course guarantee me a job?', 'row': 33}), Document(page_content='prompt: Can I add this course to my resume? If Yes, how?\\nresponse: Absolutely, we have a section in this course explaining how you can add the learnings from this course in your resume that will appeal to the hiring team.', metadata={'source': 'Can I add this course to my resume? If Yes, how?', 'row': 34})]\n"
     ]
    }
   ],
   "source": [
    "retriver = vector_db.as_retriever()\n",
    "r_docs = retriver.get_relevant_documents(\"can you provide job assistance?\")\n",
    "print(r_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "31ef757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69249823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriver,\n",
    "    input_key=\"query\",\n",
    "    return_source_documents=True,chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "574901cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Do you provide internship ? Do you have an EMI option?',\n",
       " 'result': 'Yes, and No.',\n",
       " 'source_documents': [Document(page_content='prompt: Do you provide any virtual internship?\\nresponse: Yes', metadata={'source': 'Do you provide any virtual internship?', 'row': 14}),\n",
       "  Document(page_content='prompt: Do we have an EMI option?\\nresponse: No', metadata={'source': 'Do we have an EMI option?', 'row': 13}),\n",
       "  Document(page_content='prompt: Do you provide any job assistance?\\nresponse: Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters.', metadata={'source': 'Do you provide any job assistance?', 'row': 11}),\n",
       "  Document(page_content='prompt: Does this bootcamp have lifetime access?\\nresponse: Yes', metadata={'source': 'Does this bootcamp have lifetime access?', 'row': 7})]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"Do you provide internship ? Do you have an EMI option?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "317351bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'You have machine learning couse?',\n",
       " 'result': \"I don't know.\",\n",
       " 'source_documents': [Document(page_content='prompt: Is there any prerequisite for taking this bootcamp ?\\nresponse: Our bootcamp is specifically designed for beginners with no prior experience in this field. The only prerequisite is that you need to have a functional laptop with at least 4GB ram, an internet connection, and a thrill to learn data analysis.', metadata={'source': 'Is there any prerequisite for taking this bootcamp ?', 'row': 2}),\n",
       "  Document(page_content='prompt: What dataset is used in this course? Is it some toy dataset or something that mimics a real-world problem?\\nresponse: For initial basics, we have used a toy dataset of movies but for advanced concepts, we used a dataset that is crafted to mimic the real business world by consolidating our years of experience and the FMCG industry. That dataset contains more than 1 million records.', metadata={'source': 'What dataset is used in this course? Is it some toy dataset or something that mimics a real-world problem?', 'row': 21}),\n",
       "  Document(page_content='prompt: Is there any prerequisite for taking this course?\\nresponse: The only prerequisite is that you need to have a functional laptop with at least 4GB ram, internet connection and a thrill to learn data analysis.', metadata={'source': 'Is there any prerequisite for taking this course?', 'row': 35}),\n",
       "  Document(page_content='prompt: What datasets are used in this bootcamp? Is it some toy datasets or\\n something that mimics a real-world business problem?\\nresponse: The datasets used in this bootcamp are crafted from scratch to mimic the real business world by consolidating our years of experience. The datasets not just contain more than a million rows but also cover multiple facets of the business.', metadata={'source': 'What datasets are used in this bootcamp? Is it some toy datasets or\\n something that mimics a real-world business problem?', 'row': 3})]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"You have machine learning couse?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cfc40a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
